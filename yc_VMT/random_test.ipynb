{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitanaconda3virtualenv71155691bb514feaae486d25409faffe",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Dataloader(object):\n",
    "    \"\"\"Class to Load Language Pairs and Make Batch\n",
    "    \"\"\"   \n",
    "    def __init__(self, Filename, batch_size, src_lang='en', tgt_lang='zh', v_feat='i3d', max_len=40, cuda=False, volatile=False, sort=True):\n",
    "        # Need to reload every time because memory error in pickle\n",
    "        df = pd.read_csv(Filename)\n",
    "        print(df.shape)\n",
    "        src_t = []\n",
    "        src_v = []\n",
    "        tgt = []\n",
    "        nb_pairs = 0\n",
    "        for index, row in df.iterrows():\n",
    "            src_line, tgt_line = row[src_lang], row[tgt_lang]\n",
    "            if src_line=='' and tgt_line=='':\n",
    "                break            \n",
    "            src_ids = list(map(int, src_line.strip().split()))\n",
    "            # #Remove SOS and EOS for source \n",
    "            # src_ids = src_ids[1:-1]\n",
    "            tgt_ids = list(map(int, tgt_line.strip().split()))\n",
    "            if (0 in src_ids or 0 in tgt_ids):\n",
    "                continue\n",
    "            if len(src_ids)>0 and len(tgt_ids)>0:\n",
    "                # Truncate instead of discarding the sentence\n",
    "                src_t.append(src_ids if len(src_ids)<max_len+1 else src_ids[:max_len]+[3])\n",
    "                if v_feat == 'i3d':\n",
    "                    src_v.append(row['i3d_path'])\n",
    "                tgt.append(tgt_ids if len(tgt_ids)<max_len+1 else tgt_ids[:max_len]+[3])\n",
    "                nb_pairs += 1\n",
    "        print('%d pairs are converted in the data' %nb_pairs)\n",
    "        if sort:\n",
    "            sorted_idx = sorted(range(nb_pairs), key=lambda i: len(src_t[i]))\n",
    "        else:\n",
    "            sorted_idx = [i for i in range(nb_pairs)]\n",
    "        self.src_t = [src_t[i] for i in sorted_idx]\n",
    "        self.src_v = [src_v[i] for i in sorted_idx] if src_v else []\n",
    "        self.tgt = [tgt[i] for i in sorted_idx]\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_pairs = nb_pairs\n",
    "        self.nb_batches = math.ceil(nb_pairs/batch_size)\n",
    "        self.v_feat = v_feat\n",
    "        self.cuda = cuda\n",
    "        self.volatile = volatile\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nb_batches  \n",
    "\n",
    "    def _shuffle_index(self, n, m):\n",
    "        \"\"\"Yield indexes for shuffling a length n seq within every m elements\"\"\"\n",
    "        indexes = []\n",
    "        for i in range(n):\n",
    "            indexes.append(i)\n",
    "            if (i+1)%m ==0 or i==n-1:\n",
    "                random.shuffle(indexes)\n",
    "                for index in indexes:\n",
    "                    yield index\n",
    "                indexes = []\n",
    "            \n",
    "    def shuffle(self, m):\n",
    "        \"\"\"Shuffle the language pairs within every m elements\n",
    "        \n",
    "        This will make sure pairs in the same batch still have similr length.\n",
    "        \"\"\"\n",
    "        shuffled_indexes = self._shuffle_index(self.nb_pairs, m)\n",
    "        src_t, src_v, tgt = [], [], []\n",
    "        for index in shuffled_indexes:\n",
    "            src_t.append(self.src_t[index])\n",
    "            tgt.append(self.tgt[index])\n",
    "            if self.src_v:\n",
    "                src_v.append(sefl.src_v[index])\n",
    "        self.src_t = src_t\n",
    "        self.src_v = src_v\n",
    "        self.tgt = tgt\n",
    "        \n",
    "    def _wrap(self, sentences):\n",
    "        \"\"\"Pad sentences to same length and wrap into Variable\"\"\"\n",
    "        max_size = max([len(s) for s in sentences])\n",
    "        out = [s + [0]*(max_size-len(s)) for s in sentences]\n",
    "        out = torch.LongTensor(out)\n",
    "        if self.cuda:\n",
    "            out = out.cuda()\n",
    "        return Variable(out, volatile=self.volatile)\n",
    "    \n",
    "    def _v_feat_preprocess(self, paths):\n",
    "        out = None\n",
    "        if self.v_feat == 'i3d':\n",
    "            # shape:(1, *, 1024)\n",
    "            arrays = [np.load(path) for path in paths]\n",
    "            # Pad zeros to make features have same size\n",
    "            max_size = max([a.shape[1] for a in arrays])\n",
    "            out = [np.pad(a,[(0, 0), (0, max_size-a.shape[1]), (0, 0)]) for a in arrays]\n",
    "            out = torch.tensor(out).float()\n",
    "            out = torch.squeeze(out, 1)\n",
    "        return out\n",
    "        # TODO: preprocessing for raw videos or other encoder\n",
    "        #As shapes of raw video or feature are not fixed, put them in list\n",
    "        # elif self.v_feat == 'raw'\n",
    "        # elif self.v_feat == 's3d'\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        \"\"\"Generate the i-th batch and wrap in Variable\"\"\"\n",
    "        src_t_batch = self.src_t[i*self.batch_size:(i+1)*self.batch_size]\n",
    "        src_v_batch = self.src_v[i*self.batch_size:(i+1)*self.batch_size]\n",
    "        tgt_batch = self.tgt[i*self.batch_size:(i+1)*self.batch_size]\n",
    "\n",
    "        return [self._wrap(src_t_batch), self._v_feat_preprocess(src_v_batch)], self._wrap(tgt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-2-cf3d05612818>, line 23)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-cf3d05612818>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    testdataloader = Dataloader(test_path, 1, src_lang=src_lang, tgt_lang=tgt_lang,\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from preprocess import Lang\n",
    "from Dataloader import Dataloader\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "MAX_LEN = 40\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'zh'\n",
    "run_testing_during_training = True\n",
    "preprocessing_type = 'jieba'\n",
    "print('Loading dict')\n",
    "src_dict = pickle.load(open('./data/{}/{}_dict.pkl'.format(preprocessing_type, src_lang), 'rb'))\n",
    "tgt_dict = pickle.load(open('./data/{}/{}_dict.pkl'.format(preprocessing_type, tgt_lang), 'rb'))\n",
    "print(\"Building Dataloader ...\")\n",
    "train_path = './data/{}/train.id'.format(preprocessing_type)\n",
    "valid_path = './data/{}/valid.id'.format(preprocessing_type)\n",
    "test_path = './data/{}/test.id'.format(preprocessing_type)\n",
    "\n",
    "# traindataloader = Dataloader(train_path, 1, src_lang=src_lang, tgt_lang=tgt_lang,\n",
    "#                                 v_feat='None',max_len=MAX_LEN, cuda=True)\n",
    "devdataloader = Dataloader(valid_path, 1, src_lang=src_lang, tgt_lang=tgt_lang,\n",
    "                                v_feat='None',max_len=MAX_LEN, cuda=True)\n",
    "testdataloader = Dataloader(test_path, 1, src_lang=src_lang, tgt_lang=tgt_lang,\n",
    "    at='None',max_len=MAX_LEN, cuda=True), ososort=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading dict\nBuilding Dataloader ...\n114955 pairs are converted in the data\n15000 pairs are converted in the data\n"
    }
   ],
   "source": [
    "import pickle\n",
    "from preprocess import Lang\n",
    "from Dataloader import Dataloader\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "MAX_LEN = 40\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'zh'\n",
    "run_testing_during_training = True\n",
    "preprocessing_type = 'jieba'\n",
    "print('Loading dict')\n",
    "src_dict = pickle.load(open('./data/{}/{}_dict.pkl'.format(preprocessing_type, src_lang), 'rb'))\n",
    "tgt_dict = pickle.load(open('./data/{}/{}_dict.pkl'.format(preprocessing_type, tgt_lang), 'rb'))\n",
    "print(\"Building Dataloader ...\")\n",
    "train_path = './data/{}/train.id'.format(preprocessing_type)\n",
    "valid_path = './data/{}/valid.id'.format(preprocessing_type)\n",
    "test_path = './data/{}/test.id'.format(preprocessing_type)\n",
    "\n",
    "traindataloader = Dataloader(train_path, 1, src_lang=src_lang, tgt_lang=tgt_lang,\n",
    "                                v_feat='None',max_len=MAX_LEN, cuda=True)\n",
    "# devdataloader = Dataloader(valid_path, 1, src_lang=src_lang, tgt_lang=tgt_lang,\n",
    "#                                 v_feat='None',max_len=MAX_LEN, cuda=True)\n",
    "testdataloader = Dataloader(test_path, 1, src_lang=src_lang, tgt_lang=tgt_lang, v_feat='None', max_len=MAX_LEN, cuda=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " 15\n15 13\n29 24\n17 17\n27 30\n34 15\n18 20\n15 12\n16 14\n23 19\n19 12\n21 16\n18 22\n20 16\n20 15\n22 14\n25 20\n14 14\n20 16\n18 18\n17 17\n21 16\n16 18\n14 13\n17 16\n21 14\n17 12\n13 14\n16 14\n16 16\n16 17\n17 16\n14 13\n16 17\n14 16\n14 14\n13 16\n16 13\n24 18\n19 13\n15 16\n17 15\n19 20\n28 19\n17 15\n15 18\n16 13\n14 19\n15 15\n14 18\n21 21\n15 19\n17 14\n15 15\n15 18\n24 16\n17 19\n18 20\n19 15\n17 21\n27 27\n16 19\n15 16\n22 14\n18 17\n22 17\n16 16\n17 18\n14 13\n20 17\n18 19\n25 15\n21 19\n16 12\n17 15\n26 12\n15 14\n17 15\n15 16\n13 13\n15 18\n35 14\n17 22\n16 15\n13 16\n17 17\n19 12\n16 15\n16 19\n15 15\n18 13\n17 13\n15 15\n16 13\n14 16\n16 13\n14 19\n16 16\n20 19\n16 20\n15 17\n12 15\n19 25\n17 15\n15 17\n21 22\n20 17\n16 14\n19 16\n19 19\n18 14\n22 18\n24 15\n17 17\n17 17\n16 14\n16 15\n17 18\n19 19\n18 17\n26 18\n21 16\n19 16\n16 16\n21 18\n21 21\n16 12\n17 13\n16 14\n17 16\n18 19\n24 19\n20 18\n21 17\n16 13\n16 14\n19 19\n26 14\n23 17\n17 13\n19 16\n18 17\n16 17\n20 15\n19 15\n23 17\n18 17\n16 15\n17 19\n15 15\n19 20\n15 13\n16 15\n18 18\n21 16\n20 15\n18 16\n17 20\n15 20\n17 17\n17 13\n24 19\n16 12\n13 13\n18 18\n18 15\n14 18\n19 19\n17 15\n19 15\n19 14\n22 18\n18 19\n21 14\n19 17\n43 30\n20 21\n17 16\n16 14\n14 14\n14 13\n21 17\n14 15\n14 15\n12 14\n15 13\n16 15\n15 16\n14 15\n15 15\n20 19\n16 12\n15 15\n18 15\n15 15\n17 14\n16 15\n18 18\n16 15\n20 17\n13 14\n14 16\n17 15\n15 20\n22 19\n16 14\n18 13\n15 13\n14 14\n17 17\n18 16\n17 14\n14 16\n18 22\n17 16\n16 23\n17 24\n15 15\n26 21\n21 19\n16 12\n20 20\n17 12\n22 17\n18 23\n24 21\n16 16\n18 15\n20 23\n26 19\n16 14\n17 16\n23 17\n17 16\n16 14\n24 18\n16 15\n17 16\n17 22\n20 20\n27 14\n20 17\n16 15\n28 17\n29 28\n13 16\n19 14\n20 17\n15 12\n25 15\n22 15\n20 12\n17 15\n18 20\n18 18\n19 15\n17 12\n17 15\n15 15\n21 17\n18 15\n24 17\n19 12\n23 29\n18 18\n17 15\n20 20\n18 18\n18 16\n23 16\n14 16\n16 15\n17 16\n17 17\n19 17\n22 16\n17 14\n26 23\n29 24\n23 22\n25 24\n16 17\n20 18\n15 18\n35 30\n18 15\n20 21\n15 13\n18 15\n16 17\n13 14\n19 16\n24 22\n24 16\n19 20\n15 15\n20 17\n23 26\n16 24\n21 18\n33 14\n14 13\n17 14\n14 17\n22 21\n21 16\n16 14\n17 14\n18 19\n20 18\n18 20\n16 26\n21 18\n16 16\n18 18\n19 14\n17 13\n17 21\n15 18\n17 18\n17 16\n14 16\n20 17\n21 14\n15 17\n18 18\n18 15\n19 17\n16 20\n18 16\n15 15\n17 20\n16 13\n16 19\n14 12\n17 14\n15 14\n17 16\n18 18\n18 19\n18 13\n20 24\n21 17\n17 12\n14 17\n20 17\n17 17\n19 15\n21 14\n17 19\n20 14\n21 24\n23 21\n25 18\n21 19\n17 14\n28 22\n15 12\n17 14\n14 15\n16 16\n19 19\n14 16\n17 14\n16 13\n17 14\n15 13\n21 21\n18 13\n21 18\n21 16\n19 31\n21 15\n21 18\n20 20\n19 16\n24 15\n14 15\n19 18\n21 16\n24 16\n22 20\n25 18\n19 19\n18 18\n16 15\n24 20\n15 21\n14 13\n18 16\n14 13\n16 18\n16 13\n15 16\n15 15\n18 18\n18 19\n15 16\n15 15\n22 15\n23 15\n14 17\n17 17\n17 16\n20 18\n15 15\n19 16\n17 18\n13 16\n19 16\n18 15\n28 14\n15 14\n25 15\n21 23\n19 17\n16 20\n28 17\n21 19\n17 15\n20 17\n16 13\n16 16\n18 14\n16 16\n22 17\n36 29\n18 13\n18 17\n17 16\n35 17\n16 17\n18 13\n17 15\n19 12\n27 20\n19 14\n18 13\n20 16\n24 28\n16 15\n19 18\n14 14\n18 20\n14 16\n17 16\n14 21\n17 17\n17 14\n22 20\n25 16\n17 17\n14 13\n17 19\n12 12\n16 13\n17 14\n17 14\n19 17\n19 16\n20 15\n16 14\n18 17\n18 14\n20 16\n16 14\n12 20\n20 21\n24 21\n14 15\n19 18\n24 19\n19 18\n15 16\n19 16\n18 20\n14 17\n23 23\n21 16\n15 14\n23 25\n21 16\n18 20\n18 19\n30 31\n24 17\n26 21\n22 24\n15 13\n23 35\n18 16\n22 20\n21 16\n20 13\n18 17\n18 15\n23 16\n14 12\n21 15\n13 14\n19 15\n18 16\n16 19\n17 19\n16 17\n18 20\n23 20\n16 17\n17 13\n19 18\n16 12\n18 15\n19 23\n20 19\n19 16\n25 18\n18 17\n12 13\n12 14\n14 14\n14 16\n15 16\n15 14\n18 19\n15 13\n24 16\n18 19\n21 19\n17 16\n14 14\n20 15\n18 18\n17 18\n20 17\n22 18\n17 12\n27 26\n20 21\n30 19\n19 19\n16 17\n16 20\n16 13\n17 16\n16 15\n19 17\n18 15\n17 18\n23 18\n21 17\n17 13\n23 21\n20 19\n14 16\n17 17\n15 15\n18 16\n18 19\n17 20\n16 13\n15 15\n14 16\n19 12\n20 16\n16 14\n17 15\n18 18\n17 15\n21 19\n22 19\n25 22\n16 13\n17 19\n19 17\n19 17\n15 13\n20 20\n20 18\n14 18\n15 14\n17 20\n19 16\n17 20\n21 20\n13 14\n17 14\n21 16\n17 11\n21 17\n18 15\n20 15\n19 19\n19 22\n15 28\n14 20\n20 16\n16 19\n18 15\n27 22\n19 14\n16 12\n18 21\n14 15\n14 12\n22 17\n15 15\n19 19\n19 24\n20 22\n19 17\n15 13\n22 23\n18 19\n16 17\n18 13\n19 22\n17 13\n31 37\n15 14\n14 14\n19 15\n17 21\n19 19\n24 18\n29 27\n16 21\n19 15\n15 14\n20 21\n18 17\n14 14\n15 11\n18 16\n16 15\n17 14\n23 18\n16 20\n15 14\n20 16\n14 12\n18 19\n16 14\n16 15\n13 20\n15 12\n16 17\n13 15\n26 23\n24 17\n16 16\n19 15\n21 17\n15 18\n20 20\n14 11\n18 15\n14 12\n19 19\n18 15\n15 15\n20 15\n26 23\n16 21\n19 17\n14 18\n17 14\n16 13\n14 14\n17 21\n16 21\n21 16\n24 16\n15 13\n15 13\n24 18\n25 16\n29 21\n17 18\n16 17\n21 24\n22 14\n15 23\n17 15\n17 21\n19 14\n26 17\n24 24\n26 22\n15 18\n29 26\n21 17\n22 16\n13 18\n17 21\n20 20\n20 16\n25 20\n20 14\n15 15\n22 23\n14 13\n16 13\n19 19\n15 15\n23 23\n14 17\n17 14\n18 16\n15 17\n17 15\n17 16\n17 13\n19 14\n17 22\n23 19\n17 16\n22 17\n25 15\n18 13\n15 15\n22 13\n18 15\n22 22\n22 18\n18 16\n18 15\n18 14\n17 14\n15 19\n18 16\n15 16\n19 17\n23 17\n18 23\n17 16\n15 16\n15 14\n28 20\n14 17\n29 19\n20 16\n16 17\n18 17\n16 14\n17 17\n20 17\n19 15\n15 15\n23 21\n18 15\n17 14\n27 19\n16 17\n28 18\n18 30\n17 13\n22 16\n14 15\n16 16\n18 16\n20 14\n24 21\n15 14\n16 17\n21 18\n15 13\n22 17\n32 30\n17 17\n19 18\n16 13\n18 13\n19 15\n23 15\n16 16\n14 18\n18 31\n26 20\n20 20\n15 15\n15 15\n14 13\n18 18\n16 14\n14 11\n17 16\n16 14\n16 17\n24 16\n21 17\n18 15\n22 15\n20 16\n18 17\n21 23\n18 17\n18 17\n19 15\n14 14\n16 14\n21 18\n17 15\n20 17\n38 41\n17 16\n15 15\n22 28\n20 16\n24 17\n21 26\n18 15\n21 20\n17 18\n20 17\n20 19\n19 16\n18 17\n17 14\n26 15\n37 32\n19 20\n18 16\n19 18\n19 17\n34 28\n20 15\n17 21\n21 22\n19 16\n29 16\n20 16\n20 18\n19 18\n20 16\n22 21\n20 20\n29 27\n18 20\n18 17\n20 26\n20 22\n24 26\n17 12\n16 13\n14 13\n16 18\n20 16\n15 21\n19 18\n16 19\n19 15\n19 22\n15 15\n15 17\n18 19\n18 14\n16 12\n18 19\n14 13\n17 20\n19 16\n15 15\n19 17\n19 27\n17 18\n20 16\n20 24\n17 18\n17 18\n17 20\n19 14\n20 15\n19 18\n18 16\n18 24\n23 20\n16 15\n17 14\n15 14\n16 15\n15 18\n15 14\n18 16\n16 16\n17 17\n16 16\n15 15\n19 15\n17 14\n16 16\n16 14\n23 19\n19 12\n17 12\n17 16\n23 16\n14 20\n22 21\n13 17\n17 14\n21 14\n26 28\n20 24\n15 15\n17 17\n22 18\n16 15\n21 14\n21 20\n16 12\n20 15\n22 16\n15 15\n17 15\n16 18\n15 14\n16 14\n18 14\n20 18\n18 19\n21 18\n15 14\n18 17\n16 15\n18 19\n23 13\n18 18\n20 17\n23 14\n22 15\n17 15\n17 15\n17 15\n16 14\n17 17\n20 13\n19 18\n18 15\n19 16\n15 16\n20 14\n18 13\n18 17\n23 18\n18 19\n18 21\n20 17\n22 19\n20 16\n16 29\n22 16\n22 20\n16 18\n14 14\n16 16\n15 16\n19 19\n17 17\n21 15\n18 13\n20 15\n21 17\n15 27\n14 20\n19 14\n20 21\n14 13\n17 15\n14 15\n24 21\n22 14\n16 11\n14 14\n16 17\n18 17\n24 16\n15 12\n21 24\n15 15\n17 21\n21 20\n16 17\n18 14\n20 13\n23 14\n17 16\n15 15\n17 14\n16 16\n13 14\n16 16\n18 15\n17 14\n22 17\n18 15\n17 16\n17 15\n24 21\n19 17\n14 12\n15 16\n18 15\n1719\n17 25\n17 15\n14 13\n26 21\n17 16\n16 13\n23 20\n22 15\n23 24\n17 13\n16 13\n16 17\n17 14\n20 17\n35 34\n23 14\n15 14\n17 12\n19 18\n15 14\n19 20\n16 14\n19 19\n23 20\n23 20\n22 19\n15 15\n17 14\n18 13\n16 13\n20 14\n12 11\n13 13\n14 13\n16 17\n14 14\n19 20\n15 15\n14 14\n19 15\n17 14\n16 18\n16 14\n21 23\n17 19\n18 18\n17 13\n20 20\n15 17\n23 22\n19 14\n18 18\n22 21\n22 16\n18 15\n23 23\n21 19\n19 14\n14 16\n15 19\n17 17\n21 26\n19 15\n17 19\n22 20\n18 17\n21 23\n21 18\n16 18\n17 12\n15 13\n20 20\n15 17\n21 21\n19 22\n16 11\n24 20\n15 16\n13 12\n18 14\n16 24\n15 13\n14 14\n19 13\n18 18\n18 15\n17 21\n24 15\n25 20\n16 18\n17 16\n16 23\n17 15\n18 18\n19 17\n15 15\n17 15\n17 14\n18 19\n15 19\n17 15\n24 18\n20 16\n19 17\n15 15\n15 17\n20 22\n21 18\n20 15\n21 21\n17 17\n16 13\n16 12\n15 20\n20 25\n15 16\n22 23\n13 18\n16 15\n14 16\n13 13\n20 16\n20 16\n16 18\n14 16\n23 21\n22 20\n19 20\n16 18\n17 17\n18 20\n14 18\n14 19\n14 16\n17 16\n15 16\n18 16\n15 18\n20 17\n22 22\n20 14\n18 15\n24 24\n19 15\n15 13\n15 14\n14 12\n15 14\n13 16\n16 19\n21 14\n19 16\n18 12\n26 16\n28 22\n15 14\n16 16\n16 16\n16 18\n16 16\n19 18\n19 21\n16 15\n1719\n21 20\n21 16\n15 14\n16 16\n16 16\n28 27\n17 16\n22 22\n17 16\n19 18\n17 23\n23 20\n20 22\n15 18\n17 14\n17 15\n16 16\n20 21\n36 17\n18 18\n20 19\n16 14\n19 20\n24 17\n17 17\n16 19\n15 17\n26 19\n15 16\n15 14\n17 19\n18 18\n17 16\n15 17\n17 17\n14 17\n14 15\n16 17\n14 14\n19 14\n16 14\n17 18\n16 13\n16 16\n19 16\n16 14\n14 20\n16 18\n21 25\n25 24\n16 13\n17 14\n16 16\n16 13\n26 22\n14 12\n15 19\n16 21\n16 16\n25 23\n19 18\n20 26\n19 23\n22 12\n24 18\n15 14\n27 17\n26 26\n18 14\n14 14\n21 23\n18 18\n15 13\n19 14\n19 14\n22 18\n19 17\n23 27\n17 17\n14 13\n19 21\n14 13\n22 27\n17 15\n18 13\n17 16\n18 20\n20 18\n22 25\n17 25\n19 19\n17 15\n15 18\n17 17\n19 15\n17 17\n14 19\n15 14\n28 23\n16 16\n29 28\n17 25\n16 19\n16 15\n18 12\n14 11\n13 14\n15 15\n14 15\n18 14\n15 16\n17 17\n15 12\n14 15\n14 14\n23 24\n19 15\n13 14\n16 15\n15 13\n14 12\n21 13\n16 20\n20 16\n14 18\n23 21\n17 13\n17 15\n14 16\n21 16\n23 19\n21 23\n16 14\n19 15\n39 25\n14 12\n15 17\n14 16\n16 16\n15 21\n17 16\n16 13\n15 17\n15 16\n14 17\n24 21\n14 14\n19 21\n16 15\n21 14\n27 27\n22 20\n13 15\n18 14\n17 13\n16 16\n14 13\n18 25\n21 21\n16 21\n11 19\n22 13\n22 18\n15 13\n32 21\n18 14\n21 16\n18 17\n18 17\n19 16\n15 13\n17 18\n14 13\n20 13\n18 21\n17 15\n20 19\n17 22\n18 23\n14 13\n21 19\n21 12\n21 21\n17 14\n20 13\n18 13\n14 14\n16 16\n16 14\n15 18\n23 21\n16 17\n19 18\n17 14\n15 16\n14 11\n17 13\n24 19\n18 18\n17 13\n14 17\n15 15\n18 13\n17 13\n19 13\n16 18\n18 17\n19 13\n19 15\n19 14\n19 15\n14 16\n17 17\n15 13\n17 16\n19 19\n16 13\n14 13\n17 18\n18 15\n19 18\n14 16\n16 17\n14 14\n22 22\n21 29\n22 17\n25 21\n29 12\n20 18\n24 15\n19 18\n15 14\n22 19\n21 17\n19 22\n21 16\n21 19\n18 18\n18 19\n17 16\n30 16\n20 20\n21 15\n21 15\n17 21\n17 23\n15 16\n17 18\n18 22\n26 20\n12 14\n14 17\n18 19\n12 19\n16 15\n22 29\n18 14\n15 19\n19 22\n18 20\n18 20\n14 11\n21 23\n20 15\n19 17\n16 14\n21 20\n21 13\n14 16\n20 21\n22 17\n22 22\n16 13\n29 23\n18 19\n14 17\n19 16\n17 13\n16 17\n15 13\n14 12\n26 18\n16 16\n16 17\n20 18\n17 19\n22 19\n16 14\n15 14\n18 18\n24 16\n21 15\n15 16\n22 19\n19 17\n23 19\n19 15\n14 13\n20 16\n18 17\n18 13\n22 18\n15 15\n26 25\n15 16\n17 17\n20 18\n15 18\n18 16\n16 16\n16 17\n18 14\n14 15\n19 12\n19 17\n19 16\n31 31\n15 17\n18 18\n13 14\n17 21\n15 21\n17 13\n15 14\n15 12\n18 13\n19 20\n17 17\n15 15\n14 15\n14 16\n16 18\n15 21\n19 16\n15 17\n23 15\n18 18\n15 18\n16 19\n17 15\n23 17\n21 23\n15 14\n16 14\n14 16\n18 16\n16 12\n16 16\n14 22\n17 13\n25 22\n25 21\n14 21\n20 20\n17 14\n15 13\n22 17\n22 20\n17 17\n18 15\n17 14\n15 12\n18 16\n15 15\n17 14\n19 15\n14 13\n14 14\n15 15\n22 17\n18 24\n17 23\n23 21\n15 17\n14 16\n21 19\n14 15\n22 21\n17 20\n20 12\n20 16\n20 24\n13 16\n17 19\n21 20\n17 16\n18 19\n16 13\n18 15\n17 17\n16 19\n17 19\n21 22\n19 21\n22 18\n16 14\n17 20\n20 19\n18 16\n29 17\n21 15\n15 14\n21 15\n19 14\n14 15\n17 15\n17 19\n16 16\n20 18\n20 18\n18 16\n16 16\n14 17\n15 15\n20 22\n23 16\n16 13\n22 16\n15 13\n19 18\n15 14\n17 15\n16 13\n25 16\n26 20\n29 28\n16 13\n20 15\n16 19\n18 18\n30 15\n15 15\n18 17\n13 16\n22 16\n18 18\n20 13\n25 18\n21 20\n16 19\n15 18\n15 13\n13 17\n20 20\n15 16\n18 15\n19 15\n15 13\n17 20\n22 24\n25 15\n19 20\n22 19\n20 18\n28 25\n17 15\n15 13\n14 17\n16 21\n18 18\n26 18\n17 20\n17 16\n18 14\n18 21\n20 14\n20 18\n18 20\n17 15\n14 15\n18 18\n14 12\n18 17\n19 19\n18 17\n16 17\n15 16\n15 14\n18 18\n14 15\n15 24\n18 17\n22 14\n21 18\n22 23\n20 14\n29 21\n23 19\n17 20\n39 33\n16 14\n16 13\n19 19\n17 14\n17 16\n11 14\n22 19\n20 15\n21 19\n22 17\n15 14\n22 15\n18 16\n18 15\n16 16\n21 19\n14 15\n15 15\n17 15\n16 16\n19 16\n19 17\n18 18\n18 19\n20 18\n15 15\n16 14\n18 15\n14 16\n21 16\n17 14\n21 20\n22 18\n14 15\n17 18\n14 12\n16 12\n20 20\n20 15\n26 23\n39 18\n13 13\n20 13\n18 18\n18 17\n15 13\n22 25\n15 14\n17 17\n21 18\n23 15\n17 15\n14 15\n15 20\n16 17\n29 24\n16 12\n21 15\n15 16\n18 13\n29 27\n17 24\n18 19\n22 21\n19 17\n20 13\n21 25\n16 15\n16 13\n18 17\n16 16\n22 16\n18 14\n22 17\n15 16\n15 12\n14 14\n15 13\n16 14\n14 14\n18 16\n17 17\n23 18\n14 14\n17 14\n25 16\n20 22\n14 14\n18 18\n20 22\n27 23\n15 14\n19 18\n16 25\n17 13\n18 13\n18 17\n14 15\n13 17\n21 15\n15 19\n14 16\n14 14\n17 21\n22 21\n28 23\n18 13\n20 15\n17 21\n14 13\n20 16\n16 15\n18 17\n20 12\n18 15\n19 18\n14 20\n16 14\n18 26\n25 20\n15 19\n18 20\n17 16\n16 14\n21 17\n15 12\n18 19\n19 17\n21 15\n18 20\n15 15\n22 15\n13 14\n12 14\n15 17\n14 17\n20 21\n21 18\n15 15\n16 13\n21 19\n25 19\n25 23\n17 24\n15 14\n21 19\n15 15\n16 14\n14 13\n20 16\n18 14\n16 15\n17 15\n18 17\n17 15\n20 20\n22 20\n18 14\n16 17\n16 16\n18 16\n15 16\n15 15\n16 15\n16 15\n15 15\n15 15\n14 14\n16 17\n17 16\n27 14\n26 17\n18 18\n20 20\n21 23\n21 21\n15 17\n14 14\n21 17\n16 14\n16 14\n17 16\n17 16\n19 21\n16 14\n23 11\n15 12\n18 13\n22 13\n14 19\n16 13\n17 12\n21 20\n14 13\n22 21\n18 16\n21 21\n20 17\n19 16\n15 16\n17 16\n16 16\n19 14\n24 18\n22 20\n20 17\n22 19\n17 15\n17 15\n15 17\n24 22\n19 17\n15 14\n17 16\n15 13\n24 23\n35 38\n21 14\n20 19\n15 13\n16 18\n19 15\n14 12\n15 14\n20 20\n14 12\n23 22\n17 14\n14 23\n17 14\n20 19\n17 17\n14 14\n19 18\n15 13\n17 13\n18 19\n17 16\n27 17\n17 17\n15 12\n17 12\n16 13\n15 13\n16 15\n18 13\n15 14\n16 16\n19 17\n31 22\n12 14\n27 25\n20 11\n16 14\n16 16\n16 12\n18 15\n16 15\n17 17\n18 16\n22 18\n15 15\n21 21\n19 15\n16 14\n26 18\n16 15\n15 15\n15 17\n17 19\n28 25\n24 20\n26 21\n18 21\n18 17\n16 15\n32 28\n24 18\n15 14\n18 23\n14 14\n20 20\n32 14\n17 15\n17 18\n20 20\n23 28\n19 18\n15 14\n19 14\n15 16\n18 14\n17 17\n14 16\n19 22\n16 14\n15 17\n20 22\n20 19\n17 12\n15 14\n20 19\n24 16\n18 14\n18 23\n14 13\n16 14\n17 19\n16 15\n20 16\n18 15\n17 15\n18 13\n19 17\n26 14\n19 18\n18 17\n19 10\n19 19\n18 21\n24 14\n17 13\n16 13\n16 16\n21 20\n16 16\n20 19\n16 13\n16 15\n19 17\n28 26\n18 15\n14 14\n21 14\n15 17\n21 14\n21 27\n19 15\n15 23\n20 18\n18 15\n18 20\n18 13\n27 20\n18 16\n12 15\n15 18\n15 19\n17 16\n22 24\n14 16\n18 18\n18 17\n15 18\n17 16\n28 17\n13 16\n16 15\n16 17\n15 16\n17 13\n21 21\n20 17\n22 19\n16 16\n21 13\n18 19\n23 17\n19 15\n19 17\n29 19\n28 21\n17 15\n18 16\n21 17\n25 21\n17 16\n27 15\n15 18\n19 15\n16 12\n24 16\n17 15\n17 21\n18 18\n20 18\n24 22\n24 23\n16 18\n17 16\n22 21\n20 17\n22 18\n16 19\n22 17\n19 19\n21 17\n18 12\n19 16\n19 23\n20 18\n24 17\n17 14\n17 18\n23 22\n18 14\n19 16\n20 16\n17 20\n18 15\n31 20\n14 12\n15 17\n17 13\n20 14\n16 13\n14 16\n14 13\n15 16\n17 14\n16 14\n14 10\n17 13\n15 14\n16 13\n15 14\n19 14\n16 14\n14 13\n24 29\n21 22\n25 19\n22 22\n14 12\n17 13\n22 17\n15 13\n15 18\n13 15\n21 15\n17 13\n17 14\n14 16\n24 16\n16 13\n15 14\n20 12\n15 11\n16 13\n16 15\n15 12\n19 17\n18 16\n14 17\n17 12\n14 13\n16 13\n16 14\n20 16\n14 15\n16 13\n24 20\n16 16\n13 13\n16 14\n16 11\n17 15\n16 16\n20 18\n18 17\n17 17\n17 14\n16 15\n17 17\n16 17\n14 15\n17 12\n15 18\n14 16\n18 15\n16 14\n19 17\n17 14\n14 14\n15 13\n19 16\n16 19\n19 15\n15 22\n15 16\n26 25\n14 18\n34 18\n31 19\n19 18\n19 21\n16 14\n20 15\n24 22\n17 15\n17 14\n18 20\n14 12\n17 15\n24 18\n18 18\n16 18\n18 12\n17 14\n16 14\n18 23\n16 12\n15 12\n20 21\n15 16\n16 15\n15 11\n18 19\n18 17\n14 15\n16 18\n13 15\n15 12\n17 15\n15 19\n19 18\n17 20\n20 14\n16 17\n17 22\n16 20\n16 15\n18 15\n14 13\n14 13\n17 15\n23 23\n17 15\n16 18\n18 15\n17 17\n17 15\n14 12\n18 20\n18 15\n16 18\n20 18\n15 15\n19 19\n16 16\n16 15\n20 15\n22 13\n22 20\n19 10\n16 15\n16 16\n16 14\n14 17\n17 18\n15 15\n14 16\n26 15\n17 30\n24 22\n15 18\n16 17\n25 14\n15 15\n16 15\n16 12\n19 16\n20 17\n16 15\n18 18\n22 22\n17 14\n14 14\n16 15\n21 25\n15 14\n19 14\n20 15\n20 18\n18 16\n15 28\n14 17\n24 21\n13 15\n14 15\n24 14\n19 13\n31 17\n18 20\n21 26\n18 18\n17 15\n25 14\n29 23\n26 22\n24 28\n25 24\n19 16\n38 27\n15 15\n25 14\n18 19\n21 13\n23 17\n17 11\n15 16\n15 13\n20 15\n19 19\n25 17\n15 20\n26 23\n16 15\n19 16\n24 24\n16 16\n20 15\n19 15\n19 20\n19 14\n15 14\n17 14\n16 15\n16 15\n15 16\n14 13\n27 18\n15 15\n24 17\n17 22\n19 16\n14 12\n16 15\n14 13\n19 17\n18 17\n22 19\n16 14\n15 15\n18 14\n24 24\n18 16\n19 18\n16 19\n22 17\n20 24\n22 18\n23 14\n14 14\n21 16\n15 15\n18 15\n14 15\n16 19\n24 23\n15 16\n19 24\n17 17\n16 17\n17 18\n17 13\n16 17\n21 21\n16 16\n22 20\n21 15\n21 22\n19 18\n15 12\n18 15\n16 14\n25 24\n16 15\n26 14\n16 18\n18 14\n16 16\n16 15\n15 20\n15 15\n28 30\n13 10\n16 18\n15 18\n16 17\n22 21\n18 22\n12 14\n15 17\n19 21\n14 16\n19 27\n23 20\n20 19\n19 20\n19 22\n15 17\n26 25\n17 23\n21 22\n18 15\n25 21\n19 18\n18 13\n21 20\n18 14\n19 17\n15 16\n20 15\n17 15\n19 16\n18 18\n16 17\n25 15\n12 17\n17 20\n17 16\n17 15\n15 16\n17 13\n14 15\n19 20\n13 14\n19 14\n14 14\n16 19\n17 17\n14 14\n17 15\n17 14\n19 12\n18 16\n24 21\n13 20\n27 29\n18 16\n16 14\n15 12\n18 14\n18 22\n18 14\n14 18\n20 13\n21 22\n17 17\n16 14\n15 12\n14 13\n25 20\n19 18\n16 12\n15 16\n15 13\n15 13\n18 16\n13 19\n20 20\n22 14\n19 18\n17 17\n16 20\n19 13\n18 17\n18 15\n16 16\n19 19\n20 19\n20 17\n17 16\n17 16\n13 12\n18 15\n17 14\n15 14\n15 14\n17 16\n16 20\n14 16\n17 14\n17 15\n16 16\n19 25\n22 20\n19 19\n18 15\n21 16\n17 17\n15 13\n17 14\n14 17\n21 22\n21 20\n19 19\n13 25\n22 16\n16 14\n18 16\n21 16\n18 19\n19 15\n14 14\n16 14\n17 14\n18 13\n14 19\n17 14\n19 15\n16 12\n18 15\n14 22\n16 18\n18 14\n17 16\n13 16\n15 13\n14 16\n17 20\n20 17\n21 17\n37 27\n15 13\n16 16\n19 17\n17 13\n16 19\n22 14\n17 20\n17 16\n15 14\n18 15\n15 15\n18 18\n17 13\n16 14\n19 22\n14 18\n14 16\n16 15\n15 16\n26 19\n23 21\n13 13\n16 17\n16 14\n16 14\n16 13\n17 19\n18 15\n20 20\n16 21\n23 26\n19 18\n20 20\n14 24\n22 21\n19 17\n20 15\n17 19\n15 14\n20 19\n20 19\n15 23\n16 14\n18 12\n17 21\n15 16\n19 22\n14 17\n16 19\n13 17\n18 16\n23 20\n29 27\n21 21\n22 23\n28 24\n19 21\n15 16\n15 13\n18 19\n15 16\n15 17\n16 14\n18 17\n15 16\n16 14\n16 15\n18 13\n14 14\n16 12\n17 15\n15 12\n15 14\n17 13\n16 14\n21 24\n17 26\n26 16\n35 35\n19 20\n19 20\n18 15\n14 14\n22 19\n15 14\n17 21\n18 14\n22 15\n18 23\n13 12\n20 15\n16 17\n14 14\n24 19\n14 12\n15 20\n16 17\n16 13\n17 15\n20 16\n16 15\n14 15\n15 15\n16 17\n14 18\n17 26\n15 14\n15 14\n17 15\n25 19\n17 18\n24 21\n21 16\n18 15\n15 16\n16 15\n20 22\n19 13\n15 24\n16 13\n15 15\n15 14\n19 15\n17 15\n21 19\n22 15\n17 15\n23 16\n18 16\n16 19\n21 27\n16 25\n21 15\n15 17\n16 23\n19 19\n18 15\n15 13\n20 20\n24 20\n22 20\n19 19\n21 14\n22 19\n17 16\n18 21\n18 18\n21 22\n18 23\n18 21\n18 21\n19 15\n15 19\n19 13\n18 20\n20 13\n13 17\n17 13\n16 13\n23 22\n16 21\n16 17\n19 20\n23 20\n27 27\n16 14\n32 29\n21 18\n18 17\n16 22\n17 14\n25 14\n15 11\n19 19\n16 15\n13 13\n20 16\n20 22\n12 13\n23 23\n22 19\n16 16\n18 15\n15 13\n17 20\n19 13\n15 14\n17 17\n19 16\n27 28\n20 16\n17 21\n22 15\n19 19\n18 12\n23 23\n14 18\n15 14\n20 21\n19 18\n16 17\n17 23\n29 24\n25 26\n21 20\n17 15\n20 25\n22 17\n20 16\n20 14\n17 18\n21 17\n19 17\n27 22\n28 28\n23 18\n20 20\n15 13\n21 19\n19 15\n17 14\n17 16\n22 17\n17 14\n19 19\n22 24\n26 18\n20 13\n22 22\n24 25\n18 15\n18 16\n22 23\n19 25\n14 14\n17 15\n20 15\n15 15\n17 18\n18 21\n18 16\n26 26\n18 15\n14 19\n24 25\n17 19\n30 32\n18 17\n16 15\n15 17\n21 21\n15 13\n19 14\n19 18\n18 17\n18 20\n21 20\n14 13\n16 14\n17 16\n18 17\n17 13\n14 15\n22 15\n13 14\n17 16\n15 14\n15 14\n19 18\n16 14\n13 14\n16 15\n15 13\n20 18\n14 14\n15 14\n15 14\n16 11\n15 17\n16 15\n18 14\n12 12\n16 13\n14 17\n17 16\n14 14\n14 12\n17 17\n12 14\n15 17\n27 27\n20 16\n17 13\n25 21\n17 14\n17 14\n16 14\n20 15\n15 14\n14 13\n15 15\n14 16\n19 21\n20 13\n31 22\n14 17\n18 23\n19 17\n24 22\n19 20\n22 15\n16 14\n29 15\n18 18\n23 22\n19 16\n19 15\n18 13\n15 11\n20 17\n18 17\n18 15\n19 16\n16 15\n16 16\n17 14\n18 19\n14 15\n21 19\n18 18\n26 19\n17 19\n18 15\n18 18\n18 19\n22 15\n28 25\n20 14\n28 28\n19 17\n17 30\n17 20\n19 18\n17 19\n22 22\n16 14\n24 17\n17 16\n20 17\n20 21\n26 20\n24 26\n25 17\n15 24\n22 20\n18 18\n17 15\n18 14\n18 18\n17 17\n17 22\n16 16\n19 13\n18 14\n30 21\n17 18\n22 18\n20 16\n25 22\n26 20\n16 15\n21 23\n21 15\n25 12\n15 16\n19 17\n18 17\n14 16\n15 14\n23 18\n19 25\n17 18\n15 18\n16 20\n35 36\n18 16\n26 23\n16 13\n19 19\n18 16\n18 17\n26 27\n18 18\n25 24\n18 20\n16 19\n15 20\n23 27\n14 16\n27 26\n26 12\n18 21\n14 14\n19 37\n17 13\n18 26\n16 17\n24 23\n28 41\n15 16\n14 15\n17 18\n24 25\n26 23\n19 17\n24 18\n20 16\n23 17\n15 14\n16 16\n16 14\n23 25\n17 14\n26 20\n18 17\n13 20\n16 13\n22 16\n14 22\n18 15\n15 13\n13 12\n14 13\n18 14\n22 20\n14 15\n24 16\n33 13\n23 24\n19 18\n19 17\n19 17\n18 15\n18 16\n18 15\n21 13\n15 14\n15 15\n15 15\n16 16\n23 18\n15 13\n18 15\n17 14\n23 17\n15 16\n16 15\n17 19\n19 14\n18 18\n15 14\n20 17\n15 17\n19 15\n19 16\n20 20\n16 19\n18 15\n19 14\n14 13\n15 17\n14 16\n17 14\n14 15\n19 14\n22 22\n24 20\n25 15\n17 15\n22 18\n16 15\n20 14\n16 15\n14 13\n24 19\n18 18\n17 18\n18 19\n15 16\n17 17\n16 16\n16 15\n20 16\n16 13\n18 19\n14 12\n14 13\n14 12\n14 20\n18 13\n20 15\n29 26\n14 18\n15 18\n16 18\n16 12\n16 16\n20 17\n31 15\n14 16\n18 16\n14 16\n17 19\n15 17\n19 15\n20 18\n13 14\n15 14\n19 19\n16 13\n16 17\n16 21\n20 17\n16 17\n20 15\n17 17\n19 15\n14 15\n21 16\n16 14\n22 17\n16 17\n14 15\n16 21\n13 14\n18 15\n17 15\n14 15\n18 17\n20 22\n19 18\n15 15\n28 30\n17 18\n15 15\n16 15\n18 19\n19 22\n19 16\n18 17\n18 16\n21 20\n17 17\n15 18\n16 16\n12 16\n16 15\n17 13\n17 18\n18 18\n17 18\n15 15\n27 16\n21 19\n21 13\n20 18\n16 15\n19 14\n13 23\n17 14\n19 17\n20 17\n21 16\n17 13\n22 17\n16 15\n16 13\n21 19\n15 14\n19 19\n17 16\n17 16\n16 14\n20 18\n18 17\n19 20\n30 27\n19 16\n16 15\n16 15\n16 24\n16 15\n19 17\n14 17\n19 24\n15 16\n20 27\n22 17\n20 22\n16 17\n17 17\n19 18\n21 20\n24 13\n18 18\n16 16\n16 19\n14 17\n18 23\n20 19\n18 14\n17 17\n18 18\n19 20\n16 18\n23 21\n20 16\n16 15\n16 15\n19 20\n19 18\n17 21\n20 19\n16 19\n14 12\n16 17\n17 17\n13 14\n22 22\n22 20\n23 21\n15 19\n23 17\n17 16\n14 17\n18 18\n15 18\n15 13\n18 20\n22 19\n20 17\n19 13\n23 13\n32 29\n17 14\n22 23\n17 14\n22 19\n17 16\n18 20\n17 14\n15 19\n17 17\n17 14\n21 22\n16 15\n15 26\n20 18\n19 14\n23 23\n21 22\n16 19\n23 18\n20 14\n14 17\n18 18\n16 23\n16 12\n16 16\n15 16\n17 14\n17 15\n20 14\n16 16\n15 22\n16 14\n17 12\n17 20\n17 17\n13 16\n14 14\n17 17\n15 19\n28 18\n16 13\n20 14\n14 16\n27 14\n21 19\n23 19\n14 16\n17 17\n20 20\n17 15\n17 14\n15 14\n18 17\n26 14\n15 14\n21 16\n16 12\n22 22\n29 16\n17 17\n14 19\n20 20\n26 25\n20 20\n16 14\n14 17\n27 13\n19 18\n20 18\n24 23\n16 14\n23 18\n14 12\n15 14\n15 12\n16 17\n14 15\n16 14\n15 14\n15 14\n15 15\n24 16\n15 18\n16 14\n14 14\n27 25\n16 17\n16 20\n20 17\n18 15\n22 22\n17 13\n26 15\n15 18\n18 16\n17 14\n30 24\n15 14\n14 17\n14 17\n16 16\n14 14\n15 18\n16 13\n18 20\n18 19\n17 18\n19 12\n23 18\n19 17\n15 15\n19 15\n18 19\n19 16\n23 24\n15 14\n15 18\n16 14\n14 12\n16 12\n17 35\n20 17\n21 18\n14 13\n18 19\n14 18\n16 14\n14 15\n15 16\n15 13\n23 18\n16 16\n19 17\n16 16\n24 23\n24 22\n17 20\n24 18\n21 14\n23 23\n20 17\n16 13\n14 15\n14 14\n16 20\n19 16\n21 22\n13 12\n15 13\n16 12\n18 14\n13 16\n20 14\n15 16\n22 21\n20 18\n14 12\n18 20\n17 15\n16 13\n18 18\n21 17\n21 16\n24 16\n17 17\n15 15\n22 15\n21 14\n18 15\n16 14\n15 18\n16 17\n16 14\n28 22\n16 18\n14 18\n16 22\n17 16\n15 15\n16 12\n18 14\n18 16\n16 18\n20 16\n18 19\n14 16\n23 17\n21 21\n20 19\n19 16\n27 21\n16 16\n19 18\n24 25\n19 20\n26 28\n22 15\n18 21\n15 13\n13 13\n19 24\n17 19\n15 17\n24 13\n16 11\n40 35\n24 20\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-16b0de00b796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md0/yingchen_ntu/VMT/VMT/yc_VMT/Dataloader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mtgt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_t_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_feat_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_v_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/md0/yingchen_ntu/VMT/VMT/yc_VMT/Dataloader.py\u001b[0m in \u001b[0;36m_wrap\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "for i in range(len(testdataloader)):\n",
    "    src, tgt = testdataloader[i]\n",
    "    x_t, x_v = src[0], src[1]\n",
    "    x_t = x_t.tolist()[0]\n",
    "    y = tgt.tolist()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "76"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "max([len(x) for x in traindataloader.tgt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\n\n\n\n  0%|          | 0/15000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n  6%|▌         | 878/15000 [00:00<00:01, 8773.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 13%|█▎        | 1981/15000 [00:00<00:01, 9346.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 21%|██        | 3104/15000 [00:00<00:01, 9839.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 28%|██▊       | 4244/15000 [00:00<00:01, 10259.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 36%|███▌      | 5328/15000 [00:00<00:00, 10425.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 42%|████▏     | 6234/15000 [00:00<00:00, 9804.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 49%|████▉     | 7368/15000 [00:00<00:00, 10217.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 57%|█████▋    | 8526/15000 [00:00<00:00, 10590.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 65%|██████▍   | 9690/15000 [00:00<00:00, 10882.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 72%|███████▏  | 10848/15000 [00:01<00:00, 11081.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 80%|███████▉  | 11956/15000 [00:01<00:00, 11078.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n 87%|████████▋ | 13098/15000 [00:01<00:00, 11178.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n100%|██████████| 15000/15000 [00:01<00:00, 11045.62it/s]\n"
    }
   ],
   "source": [
    "for i in tqdm(range(len(testdataloader))):\n",
    "    src_batch, tgt_batch = testdataloader[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for i in range(len(testdataloader)):\n",
    "    src_t_batch = testdataloader.src_t[i:(i+1)]\n",
    "    tgt_batch = testdataloader.tgt[i:(i+1)]\n",
    "    testdataloader._wrap(src_t_batch)\n",
    "    testdataloader._wrap(tgt_batch)\n",
    "    # if not (torch.tensor(src_batch_t) >=0).all():\n",
    "    #     print(i, src_batch_t)\n",
    "    # if not (torch.tensor(tgt_batch) >=0).all():\n",
    "    #     print(i, tgt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "testdataloader.batch_size\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(15000, 6)\n15000 pairs are converted in the data\n"
    }
   ],
   "source": [
    "testdataloader = Dataloader(test_path, 1, src_lang=src_lang, tgt_lang=tgt_lang, \n",
    "                                v_feat='None', max_len=MAX_LEN, cuda=True, volatile=True ,sort=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading dict\nBuilding Dataloader ...\n15000 pairs are converted in the data\nBuilding Model ...\n"
    }
   ],
   "source": [
    "from Layers import *\n",
    "from Model import *\n",
    "import pickle\n",
    "from preprocess import Lang\n",
    "from Dataloader import Dataloader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "# params\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "MAX_LEN = 40\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'zh'\n",
    "run_testing_during_training = True\n",
    "preprocessing_type = 'jieba'\n",
    "print('Loading dict')\n",
    "src_dict = pickle.load(open('./data/{}/{}_dict.pkl'.format(preprocessing_type, src_lang), 'rb'))\n",
    "tgt_dict = pickle.load(open('./data/{}/{}_dict.pkl'.format(preprocessing_type, tgt_lang), 'rb'))\n",
    "print(\"Building Dataloader ...\")\n",
    "train_path = './data/{}/train.id'.format(preprocessing_type)\n",
    "valid_path = './data/{}/valid.id'.format(preprocessing_type)\n",
    "test_path = './data/{}/test.id'.format(preprocessing_type)\n",
    "\n",
    "# traindataloader = Dataloader(train_path, batch_size, src_lang=src_lang, tgt_lang=tgt_lang,\n",
    "#                                 v_feat='None',max_len=MAX_LEN, cuda=True)\n",
    "# devdataloader = Dataloader(valid_path, batch_size, src_lang=src_lang, tgt_lang=tgt_lang, \n",
    "#                             v_feat='None', max_len=MAX_LEN, cuda=True, volatile=True)\n",
    "if run_testing_during_training:  \n",
    "    testdataloader = Dataloader(test_path, 1, src_lang=src_lang, tgt_lang=tgt_lang, \n",
    "                            v_feat='i3d', max_len=MAX_LEN, cuda=True, volatile=True, sort=False)  # test sentences one by one\n",
    "\n",
    "print(\"Building Model ...\")\n",
    "INPUT_DIM = src_dict.n_words + 1\n",
    "OUTPUT_DIM = tgt_dict.n_words + 1\n",
    "ENC_EMB_DIM = 512\n",
    "ENC_V_DIM = 1024\n",
    "DEC_EMB_DIM = 512\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 1024\n",
    "\n",
    "attn = Attention(ENC_HID_DIM*2, DEC_HID_DIM)\n",
    "enc_t = EncoderRNN(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM)\n",
    "enc_v = EncoderRNN_VFeat(ENC_V_DIM, ENC_HID_DIM)\n",
    "dec = AttnDecoderRNN_V(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM*2, DEC_HID_DIM, attn)\n",
    "\n",
    "model = Seq2Seq_VFeat(enc_t, enc_v, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 512]) torch.Size([1, 1, 1024]) torch.Size([1, 1, 1024])\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-13298a7a0b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# model.load_state_dict(torch.load('checkpoints/jieba/epoch1_acc_0.09_ppl_4851.24.pt'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/md0/yingchen_ntu/VMT/VMT/yc_VMT/Translator_s2s.py\u001b[0m in \u001b[0;36mtranslate_v\u001b[0;34m(self, src_id, src_vfeat)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m# predict the first word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBOS_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md0/yingchen_ntu/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/md0/yingchen_ntu/VMT/VMT/yc_VMT/Layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, enc_out_t, enc_out_v)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mattn_v_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[1, batch size, enc hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_t_applied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_v_applied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mrnn_input\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_t_applied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_v_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "from Translator_s2s import Translator\n",
    "src_batch, tgt_batch = testdataloader[0]\n",
    "x_t, x_v = src_batch[0], src_batch[1]\n",
    "x_t = x_t.tolist()[0]\n",
    "src_id = Variable(torch.LongTensor(x_t).unsqueeze(0).cuda(), volatile=True) \n",
    "# model.load_state_dict(torch.load('checkpoints/jieba/epoch1_acc_0.09_ppl_4851.24.pt'))\n",
    "translator = Translator(model)\n",
    "pred = translator.translate_v(x_t, x_v)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 14])"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "src_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "asd\n"
    }
   ],
   "source": [
    "(torch.tensor([1,2,3]) >0).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7c6e0761193b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msrc_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "src_len = hidden[0].shape[1]\n",
    "hidden = torch.tanh(nn.Linear(1024, 1024)(hidden[0].permute(1,0,2).view(src_len,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([32, 1024])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "hidden[0].permute(1,0,2).contiguous().view(32,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{4: 'asda', 5: 'asda', 1: '<unk>', 2: '<BOS>', 3: '<EOS>'}"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "a = {1: \"<unk>\", 2: \"<BOS>\", 3: \"<EOS>\", 4: 'asda', 7: 'asda'}\n",
    "a = {i+1:value for i, (key,value) in enumerate(a.items()) if i+1 > 3}\n",
    "a.update({1: \"<unk>\", 2: \"<BOS>\", 3: \"<EOS>\"})\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([32, 256])"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    " import torch.nn.functional as F\n",
    " F.softmax(hidden[0][0], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "hidden[0][0].shape == hidden[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 32, 256])"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Lang' on <module '__main__'>",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-98488741b29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpreprocessing_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jieba'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mzh_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpreprocessing_type\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/zh_dict.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'Lang' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "preprocessing_type = 'jieba'\n",
    "zh_dict = pickle.load(open('./data/'+preprocessing_type +'/zh_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Lang\n",
    "with open('./data/'+preprocessing_type +'/zh_dict.pkl', 'rb') as f:\n",
    "    zh_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8908"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "zh_dict.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/mnt/md0/yingchen_ntu/VMT/VMT/yc_VMT/data/jieba/test.id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(15000, 6)"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "15000it [00:01, 8332.19it/s]\n"
    }
   ],
   "source": [
    "import tqdm\n",
    "for i, row in tqdm.tqdm(enumerate(df.iterrows())):\n",
    "    src_line, tgt_line = row[1]['en'], row[1]['zh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[82, 33, 613, 188, 958, 84, 4, 1764]"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "src_batch[0].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'余因个'"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "'余  因个'.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}